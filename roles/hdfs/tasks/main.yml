#- name: Create service account for HDFS
#  user: name={{ hadoop.user }}
#        system=yes
#        shell={{ hadoop.user_shell }}
#        state=present
#        groups="{{ hadoop.user_groups | join(',') }}"

- name: define number of nodes
  set_fact: number_of_nodes="{{ groups['nodes'] | length | int }}"

- debug:
     msg: "Number of data nodes: {{ number_of_nodes }}"

- name: disable hdfs replication in single node
  set_fact: hdfs_replication_factor=1
  when: number_of_nodes | int < 3

- name: enable hdfs replication when cluster has more then three nodes
  set_fact: hdfs_replication_factor=3
  when: number_of_nodes | int >= 3

- debug:
     msg: "HDFS replication factor: {{ hdfs_replication_factor }}"

- name: remove pre-existent hadoop data directory
  file:
    path: "{{ hadoop.data_dir }}/"
    state: absent

- name: create hadoop data directory
  file:
    path: "{{ hadoop.data_dir }}"
    state: directory
#    owner: "{{ hadoop.user }}"
#    group: "{{ hadoop.user }}"
#  become: true

- name: remove pre-existent hadoop name directory
  file:
    path: "{{ hadoop.name_dir }}/"
    state: absent

- name: create hadoop name directory
  file:
    path: "{{ hadoop.name_dir }}"
    state: directory
#    owner: "{{ hadoop.user }}"
#    group: "{{ hadoop.user }}"
#  become: true


- name: remove pre-existent hadoop temp directory
  file:
    path: "{{ hadoop.temp_dir }}/"
    state: absent

- name: create hadoop temp directory
  file:
    path: "{{ hadoop.temp_dir }}"
    state: directory
#    owner: "{{ hadoop.user }}"
#    group: "{{ hadoop.user }}"
#  become: true

- name: create install directory
  file:
    path: "{{ install_dir }}/{{ hadoop.hadoop_install_dir }}"
    state: directory
#    owner: "{{ hadoop.user }}"
#    group: "{{ hadoop.user }}"
#  become: true

- debug:
     msg: "Downloading Hadoop from: {{ hadoop.download_location }}/hadoop-{{ hadoop.version }}/{{ hadoop.hadoop_archive }}"

- name: download hadoop
  get_url: url="{{ hadoop.download_location }}/hadoop-{{ hadoop.version }}/{{ hadoop.hadoop_archive }}" dest="{{ install_temp_dir }}/{{ hadoop.hadoop_archive }}"

- name: unarchive to the install directory
  shell: "tar -xvf {{ install_temp_dir }}/{{ hadoop.hadoop_archive }} --strip 1 --directory {{ install_dir }}/{{ hadoop.hadoop_install_dir }}"

- name: set core-site.xml
  template: src="core-site.xml.j2" dest="{{ install_dir }}/{{ hadoop.hadoop_install_dir }}/etc/hadoop/core-site.xml"

- name: set hadoop-env.sh
  template: src="hadoop-env.sh.j2" dest="{{ install_dir}}/{{ hadoop.hadoop_install_dir }}/etc/hadoop/hadoop-env.sh"

- name: set hdfs-site.xml
  template: src="hdfs-site.xml.j2" dest="{{ install_dir}}/{{ hadoop.hadoop_install_dir }}/etc/hadoop/hdfs-site.xml"

- name: set slaves
  template: src="slaves.j2" dest="{{ install_dir}}/{{ hadoop.hadoop_install_dir }}/etc/hadoop/slaves"
  become: true

# Environment setup.
- name: add hadoop profile to startup
  template:
    src: hadoop-profile.sh.j2
    dest: /etc/profile.d/hadoop-profile.sh
    mode: 0644

- name: format hdfs
  shell: "bin/hdfs namenode -format"
  args:
      chdir: "{{ install_dir}}/{{ hadoop.hadoop_install_dir }}"
  when: (inventory_hostname in groups['master'])
