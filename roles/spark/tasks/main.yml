#- name: Create service account for Spark
#  user: name={{ spark.user }}
#        system=yes
#        shell={{ spark.user_shell }}
#        state=present
#        groups="{{ spark.user_groups | join(',') }}"

- name: set spark installation path fact
  set_fact: spark_installation_dir=spark-{{ spark.version }}-bin-hadoop{{ spark.hadoop_version }}

- name: set spark archive fact
  set_fact: spark_archive=spark-{{ spark.version }}-bin-hadoop{{ spark.hadoop_version }}.tgz

- name: set spark download location fact
  set_fact: spark_download={{ spark.download_location }}/spark-{{ spark.version }}/{{ spark_archive }}


- name: check spark downloaded
  local_action: >
    command test -f {{ install_temp_dir }}/{{ spark_archive }}
  register: spark_downloaded
  failed_when: spark_downloaded.rc not in [0, 1]
  changed_when: False
  run_once: true

- debug:
     msg: "Downloading Spark from: {{ spark_download }}"

- name: download spark
  get_url: url="{{ spark_download }}" dest="{{ install_temp_dir }}/{{ spark_archive }}"
  when: spark_downloaded.rc == 1
  run_once: true

- name: download and unarchive to the install directory
  unarchive:
    src: "{{ install_temp_dir }}/{{ spark_archive }}"
    dest: "{{ install_dir }}"
#    owner: "{{ spark.user }}"
#    group: "{{ spark.user }}"
    creates: "{{ install_dir }}/{{ spark_installation_dir }}"
#  become: true

- name: create spark working directory
  file:
    path: "{{ spark.working_dir }}"
    state: directory
#    owner: "{{ spark.user }}"
#    group: "{{ spark.user }}"
#  become: true

- name: set spark-env.sh
  template: src="spark-env-sh.j2" dest="{{ install_dir }}/{{ spark_installation_dir }}/conf/spark-env.sh"

- name: set spark-defaults.conf
  template: src="spark-defaults-conf.j2" dest="{{ install_dir}}/{{ spark_installation_dir }}/conf/spark-defaults.conf"

- name: set slaves
  template: src="slaves.j2" dest="{{ install_dir}}/{{ spark_installation_dir }}/conf/slaves"

- name: start-cluster utility
  template: src="start-cluster.sh.j2" dest="{{ install_dir }}/bin/start-cluster.sh" mode=0744
  when: inventory_hostname in groups['master']

# Environment setup.
- name: add spark profile to startup
  template:
    src: spark-profile.sh.j2
    dest: /etc/profile.d/spark-profile.sh
    mode: 0644

- name: start spark
  shell: "sbin/start-all.sh"
  args:
      chdir: "{{ install_dir}}/{{ spark_installation_dir }}"
  when: inventory_hostname in groups['master']
