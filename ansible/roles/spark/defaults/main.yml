spark:
  version: 3.3.2
  hadoop_version: 3.2.4
  working_dir: /hadoop-data/spark/data
  master_port: 7077
  worker_work_port: 65000
  master_ui_port: 8080
  worker_ui_port: 8085
  conda_download_location: https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
  # download_location: https://archive.apache.org/dist/spark/spark-3.3.2/spark-3.3.2-bin-hadoop2.tgz
  download_location: https://archive.apache.org/dist/spark/spark-3.2.4/spark-3.2.4-bin-hadoop3.2.tgz
  user: "spark"               # the name of the (OS)user created for spark
  user_groups: []             # Optional list of (OS)groups the new spark user should belong to
  user_shell: "/bin/false"    # the spark user's default shell

  env_extras: {}
  defaults_extras: {}
